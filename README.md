# ğŸ° Bet365 Virtual Football API

Sistema de scraping e API REST para capturar e servir dados de Futebol Virtual da Bet365.

## âš ï¸ AVISOS IMPORTANTES

1. **Legalidade**: Este projeto Ã© apenas para fins educacionais. Web scraping pode violar os Termos de ServiÃ§o do site.
2. **Responsabilidade**: O uso deste cÃ³digo Ã© por sua conta e risco.
3. **Bet365**: NÃ£o possui API pÃºblica oficial para Futebol Virtual.
4. **ManutenÃ§Ã£o**: ProteÃ§Ãµes anti-bot e estrutura do site mudam frequentemente.

## ğŸš€ Funcionalidades

- âœ… Scraping de partidas ao vivo de Futebol Virtual
- âœ… Scraping de histÃ³rico de resultados
- âœ… Banco de dados para armazenamento
- âœ… API REST completa com FastAPI
- âœ… Scheduler para execuÃ§Ã£o automÃ¡tica
- âœ… Suporte a mÃºltiplas competiÃ§Ãµes (Mundial, Premiership, Superliga)
- âœ… Logs detalhados de execuÃ§Ã£o

## ğŸ“‹ Requisitos

- Python 3.9+
- Chrome/Chromium instalado
- ChromeDriver compatÃ­vel com versÃ£o do Chrome

## ğŸ”§ InstalaÃ§Ã£o

### 1. Clone ou baixe o projeto

```bash
cd apibet
```

### 2. Crie um ambiente virtual

```powershell
python -m venv venv
.\venv\Scripts\Activate.ps1
```

### 3. Instale as dependÃªncias

```powershell
pip install -r requirements.txt
```

### 4. Instale o ChromeDriver

```powershell
# OpÃ§Ã£o 1: Usando webdriver-manager (recomendado)
pip install webdriver-manager

# OpÃ§Ã£o 2: Download manual
# https://chromedriver.chromium.org/downloads
# Coloque no PATH do sistema
```

### 5. Configure as variÃ¡veis de ambiente

```powershell
Copy-Item .env.example .env
# Edite o arquivo .env conforme necessÃ¡rio
```

### 6. Inicialize o banco de dados

```powershell
python main.py init-db
```

## ğŸ“– Uso

### Modo 1: Scraping Ãšnico (Teste)

```powershell
python main.py once
```

### Modo 2: API REST

```powershell
python main.py api
```

Acesse a documentaÃ§Ã£o interativa em: `http://localhost:8000/docs`

### Modo 3: Scheduler AutomÃ¡tico

```powershell
python main.py scraper
```

Executa scraping automaticamente a cada X minutos (configurÃ¡vel em `.env`).

### Modo 4: Rodar Ambos (API + Scheduler)

```powershell
# Terminal 1
python main.py api

# Terminal 2
python main.py scraper
```

## ğŸ”Œ Endpoints da API

### Partidas

- `GET /matches` - Lista partidas com filtros
  - ParÃ¢metros: `competition`, `status`, `date_from`, `date_to`, `limit`, `offset`
- `GET /matches/{match_id}` - Detalhes de uma partida
- `GET /matches/live/current` - Partidas ao vivo

### Resultados

- `GET /results/recent` - Resultados recentes
  - ParÃ¢metros: `hours`, `competition`

### InformaÃ§Ãµes

- `GET /competitions` - Lista competiÃ§Ãµes disponÃ­veis
- `GET /stats` - EstatÃ­sticas gerais

### Scraper

- `GET /scraper/logs` - Logs de execuÃ§Ã£o
- `GET /scraper/status` - Status do Ãºltimo scraping
- `POST /scraper/run` - Dispara scraping manual

## ğŸ“ Estrutura do Projeto

```
apibet/
â”œâ”€â”€ main.py              # Script principal
â”œâ”€â”€ api.py               # API REST (FastAPI)
â”œâ”€â”€ scraper.py           # LÃ³gica de scraping
â”œâ”€â”€ scheduler.py         # Agendador automÃ¡tico
â”œâ”€â”€ models.py            # Modelos do banco de dados
â”œâ”€â”€ database.py          # ConexÃ£o e sessÃµes
â”œâ”€â”€ config.py            # ConfiguraÃ§Ãµes
â”œâ”€â”€ requirements.txt     # DependÃªncias
â”œâ”€â”€ .env.example         # Exemplo de variÃ¡veis
â”œâ”€â”€ .gitignore           # Arquivos ignorados
â””â”€â”€ logs/                # Logs da aplicaÃ§Ã£o
```

## âš™ï¸ ConfiguraÃ§Ãµes (.env)

```ini
# Banco de dados
DATABASE_URL=sqlite:///./bet365_virtual.db

# API
API_HOST=0.0.0.0
API_PORT=8000

# Scraper
SCRAPER_INTERVAL_MINUTES=5
SCRAPER_HEADLESS=True

# Bet365 URLs
BET365_URL=https://www.bet365.com/#/AVR/B146/R^1/
BET365_RESULTS_URL=https://extra.bet365.com/results
```

## ğŸ› ï¸ Desenvolvimento

### âš ï¸ IMPORTANTE: Adaptar Seletores HTML

O arquivo `scraper.py` contÃ©m seletores CSS **fictÃ­cios** que precisam ser adaptados:

1. Acesse o site da Bet365
2. Inspecione o HTML das partidas
3. Identifique os seletores corretos
4. Atualize os mÃ©todos `_parse_match_element()` e `_parse_result_element()`

### MÃ©todo Alternativo: Interceptar RequisiÃ§Ãµes

Se o site carrega dados via API interna (JSON), pode ser mais eficiente:

```python
# Usar Selenium Wire ou Playwright para capturar requisiÃ§Ãµes XHR/Fetch
# Exemplo com Playwright:
from playwright.sync_api import sync_playwright

def intercept_requests():
    with sync_playwright() as p:
        browser = p.chromium.launch()
        page = browser.new_page()
        
        # Interceptar requisiÃ§Ãµes
        page.on("response", lambda response: 
            print(response.url, response.status)
        )
        
        page.goto("https://www.bet365.com/...")
        # Filtrar URLs relevantes e extrair JSON
```

## ğŸ“Š Banco de Dados

### Tabelas

1. **virtual_matches** - Partidas de futebol virtual
2. **virtual_match_markets** - Mercados especÃ­ficos
3. **scraper_logs** - Logs de execuÃ§Ã£o

### Exemplos de Queries

```python
from database import get_db
from models import VirtualMatch

with get_db() as db:
    # Ãšltimas 10 partidas
    matches = db.query(VirtualMatch).order_by(
        VirtualMatch.match_date.desc()
    ).limit(10).all()
    
    # Partidas ao vivo
    live = db.query(VirtualMatch).filter(
        VirtualMatch.status == 'live'
    ).all()
```

## ğŸ› Troubleshooting

### Erro: ChromeDriver nÃ£o encontrado

```powershell
pip install webdriver-manager
```

Ou baixe manualmente em: https://chromedriver.chromium.org/

### Erro: Cloudflare/Captcha

O site detectou bot. SoluÃ§Ãµes:

1. Use proxy rotativo
2. Implemente delay entre requisiÃ§Ãµes
3. Use Playwright Stealth
4. Considere serviÃ§os de bypass (Bright Data, ScraperAPI)

### Erro: Seletores nÃ£o encontram elementos

Atualize os seletores CSS no `scraper.py` conforme estrutura real do site.

## ğŸ“ TODO / Melhorias Futuras

- [ ] Implementar captura de odds
- [ ] Adicionar mais mercados (Over/Under, Ambas Marcam, etc.)
- [ ] Sistema de notificaÃ§Ãµes (Telegram, Discord)
- [ ] Dashboard web para visualizaÃ§Ã£o
- [ ] Docker/Docker Compose
- [ ] Testes automatizados
- [ ] CI/CD pipeline
- [ ] Backup automÃ¡tico do banco

## ğŸ“„ LicenÃ§a

Este projeto Ã© apenas para fins educacionais. Use por sua conta e risco.

## ğŸ¤ ContribuiÃ§Ãµes

Este Ã© um projeto de exemplo. Adapte conforme suas necessidades.

## ğŸ“ Suporte

Para dÃºvidas sobre implementaÃ§Ã£o, consulte:
- DocumentaÃ§Ã£o do Selenium: https://selenium-python.readthedocs.io/
- DocumentaÃ§Ã£o do FastAPI: https://fastapi.tiangolo.com/
- DocumentaÃ§Ã£o do Playwright: https://playwright.dev/python/

---

**Lembrete Final**: Sempre verifique a legalidade do web scraping na sua jurisdiÃ§Ã£o e respeite os Termos de ServiÃ§o dos sites.
